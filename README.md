# OpsVoice Assistant ğŸš€

Voiceâ€‘powered AI observability assistant built with **Google Cloud Vertex AI / Gemini** and **Datadog APM**.  
Built for the **AI Partner Catalyst Hackathon** to showcase endâ€‘toâ€‘end monitoring of an LLMâ€‘powered backend.

---

## ğŸ“Œ Overview

opsvoice-assistant/
â”œâ”€â”€ venv/                             # Python virtual environment (excluded from repo)
â”œâ”€â”€ main.py                           # Flask app with Datadog + Vertex AI integration
â”œâ”€â”€ README.md                         # Project overview, setup, and submission details
â”œâ”€â”€ requirements.txt                  # Python dependencies
â”œâ”€â”€ Connect-Datadog-with-docker.md    # Optional guide or notes


OpsVoice Assistant is a Flaskâ€‘based backend service that:
- Accepts voice command requests (`/process-command`)
- Simulates **speechâ€‘toâ€‘text** (Google STT)
- Runs **LLM analysis** (Vertex AI Gemini)
- Streams **traces, logs, and metrics** to **Datadog APM**
- Provides **dashboards and monitors** for latency, errors, and downstream service health

---

## ğŸ›  Tech Stack

- **Python 3.11**
- **Flask** (REST API)
- **Google Cloud Vertex AI / Gemini**
- **Datadog APM (`ddtrace`)**
- **Datadog Agent** (local, port `8126`)
- **DogStatsD** (custom metrics)

---

## âš™ï¸ Setup Instructions

### 1. Clone the Repository
```bash
git clone https://github.com/<your-username>/opsvoice-assistant.git
cd opsvoice-assistant
```

2. Install Dependencies

```bash
pip install -r requirements.txt
```

3. Run the Backend

```bash
python main.py
```

4. ğŸ” Observability
- Datadog Agent must be running locally (localhost:8126)
- Logs include trace_id and span_id for correlation
- Dashboards track latency, error rate, and model usage
- Monitors can be configured for:
- Latency thresholds
- Error rate > 5%
- Model usage anomalies


5. ğŸ“¡ API Endpoints
- GET /status â†’ Health check
- GET /model-info â†’ Gemini model list
- POST /process-command â†’ Voice command processing








